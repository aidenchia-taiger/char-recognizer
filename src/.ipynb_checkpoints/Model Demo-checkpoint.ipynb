{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from model import ModelFactory\n",
    "from Utils import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] filterVals: [8, 16, 32, 64]\n",
      "[INFO] numEpochs: 50\n",
      "[INFO] numClasses: 53\n",
      "[INFO] batchSize: 32\n",
      "[INFO] strideVals: [1, 1, 1, 1]\n",
      "[INFO] poolVals: [2, 2, 2, 1]\n",
      "[INFO] learningRate: 0.01\n",
      "[INFO] imgSize: (32, 32, 1)\n",
      "[INFO] savepath: ../models/model.h5\n",
      "[INFO] dropoutRatio: 0.6\n",
      "[INFO] kernelVals: [4, 4, 4, 4]\n",
      "[INFO] logpath: ../logs/Time_1743_Date_05-07_model\n",
      "[INFO] modelName: model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 8)         136       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        2064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 53)                6837      \n",
      "=================================================================\n",
      "Total params: 574,957\n",
      "Trainable params: 574,733\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ModelFactory(modelName='model', batchSize=32, numClasses=53, imgSize=(32,32,1), dropoutRatio=0.6,\n",
    "                     filterVals=[8,16,32,64], kernelVals=[4,4,4,4], poolVals=[2,2,2,1], strideVals=[1,1,1,1],\n",
    "                     learningRate=0.01, numEpochs=50).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "import os\n",
    "import cv2\n",
    "for root, _, files in os.walk('../imgs/validation/'):\n",
    "    for file in files:\n",
    "        if '.png' not in file:\n",
    "            continue\n",
    "        X.append(cv2.imread(os.path.join(root, file), cv2.IMREAD_GRAYSCALE))\n",
    "        Y.append(root.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "idx = randint(0, len(Y))\n",
    "print(Y[idx])\n",
    "display(X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12163 images belonging to 53 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory('../imgs/validation', batch_size=1, \n",
    "                                                    target_size =(32,32), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '#',\n",
       " 1: '$',\n",
       " 2: '(',\n",
       " 3: ')',\n",
       " 4: '0',\n",
       " 5: '1',\n",
       " 6: '2',\n",
       " 7: '3',\n",
       " 8: '4',\n",
       " 9: '5',\n",
       " 10: '6',\n",
       " 11: '7',\n",
       " 12: '8',\n",
       " 13: '9',\n",
       " 14: '@',\n",
       " 15: 'A',\n",
       " 16: 'B',\n",
       " 17: 'C',\n",
       " 18: 'D',\n",
       " 19: 'E',\n",
       " 20: 'F',\n",
       " 21: 'G',\n",
       " 22: 'H',\n",
       " 23: 'I',\n",
       " 24: 'J',\n",
       " 25: 'K',\n",
       " 26: 'L',\n",
       " 27: 'M',\n",
       " 28: 'N',\n",
       " 29: 'O',\n",
       " 30: 'P',\n",
       " 31: 'Q',\n",
       " 32: 'R',\n",
       " 33: 'S',\n",
       " 34: 'T',\n",
       " 35: 'U',\n",
       " 36: 'V',\n",
       " 37: 'W',\n",
       " 38: 'X',\n",
       " 39: 'Y',\n",
       " 40: 'Z',\n",
       " 41: 'a',\n",
       " 42: 'b',\n",
       " 43: 'd',\n",
       " 44: 'e',\n",
       " 45: 'f',\n",
       " 46: 'g',\n",
       " 47: 'h',\n",
       " 48: 'n',\n",
       " 49: 'q',\n",
       " 50: 'r',\n",
       " 51: 'slash',\n",
       " 52: 't'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = valid_generator.class_indices\n",
    "inv_mapping = {v:k for k,v in mapping.items()}\n",
    "#inv_mapping\n",
    "inv_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(X)):\\n    x = cv2.resize(X[i], (32, 32))\\n    x = np.expand_dims(x, axis=0)\\n    x = np.expand_dims(x, axis=-1)\\n    #print(np.argmax(model.predict(x)))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in valid_generator.next():\n",
    "    print(len(i))\n",
    "    #model.predict(x)\n",
    "    #print(y)\n",
    "'''\n",
    "for i in range(len(X)):\n",
    "    x = cv2.resize(X[i], (32, 32))\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    #print(np.argmax(model.predict(x)))\n",
    "'''\n",
    "#     pred = inv_mapping[np.argmax(model.predict(x))]\n",
    "#     print('Ground Truth: {}, Prediction: {}'.format(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_generator.next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
